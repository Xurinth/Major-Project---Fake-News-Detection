{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1694b769-1090-4576-a95e-31397fe94dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from transformers import BertPreTrainedModel, BertConfig\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddbd9fcf-9bed-44b7-936d-0816ca6a08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\suraj\\\\OneDrive\\\\Desktop\\\\DATASETS\\\\NewCleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94f6e010-5672-43ae-b86e-92793ea1b6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label    False\n",
      "texts    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "null_counts = df.isnull().any()\n",
    "print (null_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a23b048f-d183-4b4c-8b03-f303f5ae96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non-alphabetic characters with space\n",
    "df['cleaned_text'] = df['texts'].replace('[^a-zA-Z]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68bbb938-be7d-45f5-bd33-727199eda9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text data\n",
    "def clean_text(text):\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    # Remove URLs\n",
    "    import re\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Remove extra whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    text = re.sub(r\"â€™\", \"'\", text)  # Replace â€™ with '\n",
    "    return text\n",
    "\n",
    "df[\"new_texts\"] = df[\"cleaned_text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f59e0334-b7d1-4223-ac5a-69b44deac180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>texts</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>new_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A whirlwind day in D.C. showcases TrumpÃ¢Â€Â™s...</td>\n",
       "      <td>A whirlwind day in D C  showcases Trump      s...</td>\n",
       "      <td>whirlwind day c showcases trump unorthodox vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In Baltimore's call for federal police probe, ...</td>\n",
       "      <td>In Baltimore s call for federal police probe  ...</td>\n",
       "      <td>baltimore call federal police probe new search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Trump Proudly Declares: Most Of The People IÃ¢...</td>\n",
       "      <td>Trump Proudly Declares  Most Of The People I  ...</td>\n",
       "      <td>trump proudly declares people insulted deserve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Inside the Trump-Bush melodrama: Decades of te...</td>\n",
       "      <td>Inside the Trump Bush melodrama  Decades of te...</td>\n",
       "      <td>inside trump bush melodrama decades tension di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Shutdown clash to return in force by December ...</td>\n",
       "      <td>Shutdown clash to return in force by December ...</td>\n",
       "      <td>shutdown clash return force december notable n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              texts  \\\n",
       "0      0  A whirlwind day in D.C. showcases TrumpÃ¢Â€Â™s...   \n",
       "1      0  In Baltimore's call for federal police probe, ...   \n",
       "2      1  Trump Proudly Declares: Most Of The People IÃ¢...   \n",
       "3      0  Inside the Trump-Bush melodrama: Decades of te...   \n",
       "4      0  Shutdown clash to return in force by December ...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  A whirlwind day in D C  showcases Trump      s...   \n",
       "1  In Baltimore s call for federal police probe  ...   \n",
       "2  Trump Proudly Declares  Most Of The People I  ...   \n",
       "3  Inside the Trump Bush melodrama  Decades of te...   \n",
       "4  Shutdown clash to return in force by December ...   \n",
       "\n",
       "                                           new_texts  \n",
       "0  whirlwind day c showcases trump unorthodox vie...  \n",
       "1  baltimore call federal police probe new search...  \n",
       "2  trump proudly declares people insulted deserve...  \n",
       "3  inside trump bush melodrama decades tension di...  \n",
       "4  shutdown clash return force december notable n...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68bedda4-4eb9-4138-928c-5b4049db9143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0s: 42760\n",
      "Count of 1s: 42760\n"
     ]
    }
   ],
   "source": [
    "label_counts = df['label'].value_counts()\n",
    "print(\"Count of 0s:\", label_counts[0])\n",
    "print(\"Count of 1s:\", label_counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4dc4058-ee2f-429d-8069-b4e1d21b9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9052aaf-a4f9-43eb-8fee-2df5539703ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the texts\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the max length for the input texts\n",
    "max_length = 512\n",
    "\n",
    "# Tokenize and encode the texts\n",
    "train_encodings = tokenizer(list(train_data['new_texts'].values), truncation=True, padding=True, max_length=max_length)\n",
    "val_encodings = tokenizer(list(val_data['new_texts'].values), truncation=True, padding=True, max_length=max_length)\n",
    "test_encodings = tokenizer(list(test_data['new_texts'].values), truncation=True, padding=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87c3adad-6c33-4fa6-9897-cb0cdbf5f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch tensors for the input data\n",
    "train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']),\n",
    "                              torch.tensor(train_encodings['attention_mask']),\n",
    "                              torch.tensor(train_data['label'].values))\n",
    "\n",
    "val_dataset = TensorDataset(torch.tensor(val_encodings['input_ids']),\n",
    "                            torch.tensor(val_encodings['attention_mask']),\n",
    "                            torch.tensor(val_data['label'].values))\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(test_encodings['input_ids']),\n",
    "                             torch.tensor(test_encodings['attention_mask']),\n",
    "                             torch.tensor(test_data['label'].values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ea0187-738a-4ece-8805-fccacd4d224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5b3f771-8316-4d2c-aaa0-ac3fbbe1fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the max length for the input texts\n",
    "max_length = 512\n",
    "\n",
    "# Tokenize and encode the texts\n",
    "train_encodings = tokenizer(list(train_data['texts'].values), truncation=True, padding=True, max_length=max_length)\n",
    "val_encodings = tokenizer(list(val_data['texts'].values), truncation=True, padding=True, max_length=max_length)\n",
    "test_encodings = tokenizer(list(test_data['texts'].values), truncation=True, padding=True, max_length=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4928ea7-3618-491b-9d32-478048c5633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71e8853a-772c-4d02-a212-7a4c1246ab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the custom BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbe2b791-c612-4ed6-b9f9-cc3588b5dfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfe4c898-61bb-4d2c-89d5-5793a094dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "# Set the optimizer and learning rate scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_loader) * num_epochs # Number of training epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ad1a79e-ad29-4530-abb6-95c91d9dae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store accuracy history\n",
    "train_acc_history = []\n",
    "val_acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1be9b49d-de7d-4652-86bb-24706495f085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3421/3421 [59:06<00:00,  1.04s/it, loss=0.000744]  \n",
      "100%|██████████| 856/856 [05:17<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Time: 3864.21s - Remaining: 7728.42s\n",
      "Training Accuracy: 0.9635 - Validation Accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3421/3421 [56:03<00:00,  1.02it/s, loss=0.000273]\n",
      "100%|██████████| 856/856 [04:18<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Time: 3622.07s - Remaining: 3622.07s\n",
      "Training Accuracy: 0.9886 - Validation Accuracy: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3421/3421 [55:28<00:00,  1.03it/s, loss=0.000198]\n",
      "100%|██████████| 856/856 [04:43<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Time: 3612.18s - Remaining: 0.00s\n",
      "Training Accuracy: 0.9967 - Validation Accuracy: 0.9871\n",
      "Average Training Accuracy: 0.9829\n",
      "Average Validation Accuracy: 0.9845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "    start_time = time()\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "    for batch in train_pbar:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "        train_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "    train_acc_history.append(train_accuracy)\n",
    "\n",
    "    # Evaluation on the validation set\n",
    "    model.eval()\n",
    "    val_pbar = tqdm(val_loader, position=0, leave=True)\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    for batch in val_pbar:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    val_acc_history.append(val_accuracy)\n",
    "\n",
    "    end_time = time()\n",
    "    epoch_time = end_time - start_time\n",
    "    remaining_time = epoch_time * (num_epochs - epoch - 1)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Time: {epoch_time:.2f}s - Remaining: {remaining_time:.2f}s')\n",
    "    print(f'Training Accuracy: {train_accuracy:.4f} - Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Calculate average training and validation accuracy\n",
    "avg_train_acc = sum(train_acc_history) / num_epochs\n",
    "avg_val_acc = sum(val_acc_history) / num_epochs\n",
    "print(f'Average Training Accuracy: {avg_train_acc:.4f}')\n",
    "print(f'Average Validation Accuracy: {avg_val_acc:.4f}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2a73949-4471-472e-b5e9-f57dd8b73d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1069/1069 [06:06<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results (Per Class):\n",
      "Test Precision: [0.98662913 0.98962462]\n",
      "Test Recall: [0.98953064 0.98674881]\n",
      "Test F1-Score: [0.98807776 0.98818462]\n",
      "\n",
      "Overall Test Results:\n",
      "Test Accuracy: 0.9881\n",
      "Test F1-Score (Macro): 0.9881\n",
      "Test Precision (Macro): 0.9881\n",
      "Test Recall (Macro): 0.9881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "test_pbar = tqdm(test_loader, position=0, leave=True)\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "for batch in test_pbar:\n",
    "    input_ids = batch[0].to(device)\n",
    "    attention_mask = batch[1].to(device)\n",
    "    labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    test_preds.extend(preds.cpu().numpy())\n",
    "    test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute overall accuracy\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "# Compute per-class metrics\n",
    "test_precision = precision_score(test_labels, test_preds, average=None)\n",
    "test_recall = recall_score(test_labels, test_preds, average=None)\n",
    "test_f1 = f1_score(test_labels, test_preds, average=None)\n",
    "\n",
    "# Print per-class metrics\n",
    "print('Test Results (Per Class):')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1-Score: {test_f1}')\n",
    "\n",
    "# Print overall metrics\n",
    "print('\\nOverall Test Results:')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test F1-Score (Macro): {f1_score(test_labels, test_preds, average=\"macro\"):.4f}')\n",
    "print(f'Test Precision (Macro): {precision_score(test_labels, test_preds, average=\"macro\"):.4f}')\n",
    "print(f'Test Recall (Macro): {recall_score(test_labels, test_preds, average=\"macro\"):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58ec737d-205b-480d-b9d3-0898a151f1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the desired name for the model:  PT08v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to E:\\Major Project\\Models\\PT08v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Fixed path for saving the model\n",
    "save_dir = \"E:\\\\Major Project\\\\Models\"\n",
    "\n",
    "# Prompt the user for the model name\n",
    "model_name = input(\"Enter the desired name for the model: \")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model_to_save.save_pretrained(model_path)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "745523ee-6e66-4d50-b2cf-4f85ffd5f08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Name:  Pt08v2 results april 23rd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to E:\\Major Project\\Models\\updates\\Pt08v2 results april 23rd\n"
     ]
    }
   ],
   "source": [
    "# Save results to a text file\n",
    "import os\n",
    "\n",
    "# Fixed path for saving the results file\n",
    "results_file_path = \"E:\\\\Major Project\\\\Models\\\\updates\"\n",
    "\n",
    "# Prompt the user for the file name\n",
    "results_file_name = input(\"Name: \")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(results_file_path, exist_ok=True)\n",
    "\n",
    "# Create the full file path\n",
    "results_file = os.path.join(results_file_path, results_file_name)\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(results_file, 'w') as f:\n",
    "    # Write the training accuracy history\n",
    "    f.write('Training Accuracy History:\\n')\n",
    "    for epoch, acc in enumerate(train_acc_history):\n",
    "        f.write(f'Epoch {epoch + 1}: {acc:.4f}\\n')\n",
    "    f.write('\\n')\n",
    "\n",
    "    # Write the validation accuracy history\n",
    "    f.write('Validation Accuracy History:\\n')\n",
    "    for epoch, acc in enumerate(val_acc_history):\n",
    "        f.write(f'Epoch {epoch + 1}: {acc:.4f}\\n')\n",
    "    f.write('\\n')\n",
    "\n",
    "    # Write the average training and validation accuracy\n",
    "    f.write(f'Average Training Accuracy: {avg_train_acc:.4f}\\n')\n",
    "    f.write(f'Average Validation Accuracy: {avg_val_acc:.4f}\\n\\n')\n",
    "\n",
    "    # Write the test results\n",
    "    f.write('Test Results:\\n')\n",
    "    f.write(f'Test Accuracy: {test_accuracy:.4f}\\n')\n",
    "    f.write(f'Test F1-Score: {test_f1.mean():.4f}\\n')  # Convert to scalar\n",
    "    f.write(f'Test Precision: {test_precision.mean():.4f}\\n')  # Convert to scalar\n",
    "    f.write(f'Test Recall: {test_recall.mean():.4f}\\n\\n')  # Convert to scalar\n",
    "\n",
    "    # Write the per-class test results\n",
    "    f.write('Test Results (Per Class):\\n')\n",
    "    f.write('Test Precision: ')\n",
    "    for value in test_precision:\n",
    "        f.write(f'{value:.4f} ')\n",
    "    f.write('\\n')\n",
    "    f.write('Test Recall: ')\n",
    "    for value in test_recall:\n",
    "        f.write(f'{value:.4f} ')\n",
    "    f.write('\\n')\n",
    "    f.write('Test F1-Score: ')\n",
    "    for value in test_f1:\n",
    "        f.write(f'{value:.4f} ')\n",
    "    f.write('\\n')\n",
    "\n",
    "print(f'Results saved to {results_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c05cb-8227-47af-a0ac-a8ce371ef537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
